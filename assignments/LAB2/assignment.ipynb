{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734921dc-f2b3-4314-93f4-65e3d7248da0",
   "metadata": {},
   "source": [
    "# Lab 2: Algorithmic Decision Making 2\n",
    "\n",
    "In this assignment, you will learn about how to observe and interpret the impact different features have on a machine learning model.\n",
    "Additionally, you will learn about a real-world controversy with a potentially biased machine learning model.\n",
    "\n",
    "This assignment is intended to be done collaboratively.  You will work as a group to complete the coding and written portions of this assignment.\n",
    "However, **each group member will submit a copy of the code** via the autograder and **the group will jointly submit one version of the written portion** via Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcc24d-0d45-4cb6-ae08-b81ae5bacbbb",
   "metadata": {},
   "source": [
    "## Part 0: Criminal Recidivism\n",
    "\n",
    "By its nature, machine learning is uncertain.\n",
    "This uncertainty can be acceptable in many of the countless domains where machine learning can be useful.\n",
    "We can excuse a model for returning an irrelevant search result,\n",
    "or a Pacman AI agent for taking a suboptimal path.\n",
    "However, there are some domains where mistakes can come at the cost of human pain or suffering.\n",
    "Domains where the cost of mistakes are so great,\n",
    "one can question whether we should be using machine learning at all.\n",
    "In this lab, we will skim the surface of one such domain: criminal recidivism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97ebed-6cd3-41f9-a2b2-e8ce05a4e37a",
   "metadata": {},
   "source": [
    "### COMPAS\n",
    "\n",
    "In the US justice system, before you are sentenced, paroled, or the terms of your bail are set\n",
    "(all steps that may result in incarceration)\n",
    "a judge or committee is supposed to assess your risk for future crime (nonviolent or violent),\n",
    "this act of committing future crime is called **criminal recidivism**.\n",
    "If you are considered low risk you may get more favorable treatment (a lower sentence, early parole, a low bail),\n",
    "but if you are considered high risk then you get the opposite treatment.\n",
    "COMPAS is software that was developed to do this risk assessment instead of humans.\n",
    "\n",
    "As a promising machine learner,\n",
    "you should already be very cautious about a system that decides whether people will spend more time in jail.\n",
    "(Especially since we are discussing it during an ethics class.)\n",
    "\n",
    "The nonprofit organization [ProPublica](https://en.wikipedia.org/wiki/ProPublica)\n",
    "did a [study on COMPAS](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) and found it to be racist.\n",
    "ProPublica found that COMPAS was more likely to incorrectly label black defendants as high risk,\n",
    "and less likely to label white defendants as high risk.\n",
    "In more precise terms, if COMPAS' predictive task was a binary classification where high risk is the positive label,\n",
    "black defendants have a higher false positive rate (FPR)\n",
    "while white defendants have a higher false negative rate (FNR).\n",
    "NorthPoint, the company that makes COMPAS, responded that the predictive parity between the groups is the same,\n",
    "and therefore the model is not biased/racist.\n",
    "\n",
    "What we see here is not so much an argument about the data (or even the model),\n",
    "but really an argument about what metrics are most appropriate for this situation.\n",
    "We have already talked about evaluation metrics and how there are [dozens of them](https://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "But here we are talking about [fairness metrics](https://en.wikipedia.org/wiki/Fairness_(machine_learning)#Mathematical_formulation_of_group_fairness_definitions)\n",
    "(measures of how fair a machine learning model is).\n",
    "Like evaluation metrics, there are many different fairness metrics.\n",
    "In fact, if we consider fairness to be defined by a metric, then there are at least 14 different definitions of fairness!\n",
    "To make it even more difficult, it is mathematically impossible to guarantee that all fairness metrics can be satisfied at the same time.\n",
    "\n",
    "As with many things in machine learning, this situation comes down to trade-offs and expertise.\n",
    "There is not an automatic way to just say: this is the right fairness metric.\n",
    "It is up to you as the expert to decide what is the most appropriate set of fairness metrics to use in a specific scenario.\n",
    "The \"right\" answer is to usually pick a set of fairness metrics that best fit your scenario\n",
    "while always keeping in mind how an unfair model can change people's lives.\n",
    "\n",
    "Here are some resources if you want to read more about the COMPAS controversy:\n",
    " - [Wikipedia Entry for the COMPAS Software](https://en.wikipedia.org/wiki/COMPAS_(software))\n",
    " - [Lecture Slides that Discuss COMPAS and Fairness](https://web.stanford.edu/class/cs329t/2021/slides/fairness-Week1.pdf)\n",
    " - [Initial ProPublica Article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\n",
    "   - [More Information on ProPublica Methodology](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)\n",
    "\n",
    "Now that we have talked about fairness metrics,\n",
    "let's take a look at our data for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c949fbfd-7f8f-45f7-98cb-331f4070d74c",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: x-large\";>♦ Group Break</h3>\n",
    "\n",
    "Take a moment to discus the COMPAS controversy.\n",
    "\n",
    "Some potential things to discuss with your group:\n",
    " - Do you believe that ProPublica is correct that the COMPAS model is racist?\n",
    " - Do you believe that NorthPoint is correct that the COMPAS model is fair?\n",
    " - What are your opinions on using a machine learning model to predict criminal recidivism?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4e38b-8248-4f7e-84ce-37f3db3dbf50",
   "metadata": {},
   "source": [
    "## Part 1: Data and Initial Model\n",
    "\n",
    "For this lab, we will be using data on criminal recidivism from Broward County in Florida\n",
    "(this is the same county from which ProPublica gathered data to analyze the COMPAS algorithm).\n",
    "\n",
    "Each row in the data contains information on one individual who was charged with a crime in Broward County as some point in the past.\n",
    "Each data instance contains a number of features (described below) for that individual,\n",
    "and also contains an output value that indicates if that individual went on to recidivate (commit another crime) in the future.\n",
    "\n",
    "The data has already been mostly cleaned, transformed, and split for you,\n",
    "and exists in two files:\n",
    "`recidivism-training-data.csv` which contains training data\n",
    "and `recidivism-testing-data.csv` which contains testing data.\n",
    "\n",
    "All attributes have been converted into binary features.\n",
    "This generally means that continuous values were binarized with a thresholded\n",
    "(e.g. everything under 0.5 was converted to 0.0 and the rest was converted to 1.0) \n",
    "and non-numeric values were [One-Hot encoded](https://en.wikipedia.org/wiki/One-hot).\n",
    "In One-Hot encoding, we take all the possible values an item can take and assign each possible value an index.\n",
    "Presence of that value results in a 1, and absence results in a 0.\n",
    "Essentially, we are turning a list of items into a series of binary columns which ask \"Do you have this value?\".\n",
    "The last column (`Recidivate`) is the label:\n",
    "`0` for an individual that did not recidivate\n",
    "and `1` for an individual that did recidivate.\n",
    "\n",
    "### Features\n",
    "\n",
    "The features for each individual are as follows:\n",
    "\n",
    "**Juvenile Felony Count** --\n",
    "A count of the number of felony convictions this individual has as a minor (juvenile).\n",
    "Originally, this feature was simply an integer value,\n",
    "but for this assignment it was transformed into a feature with four categorical values representing ranges/bins of counts.\n",
    "Those bins are:\n",
    " - Count = 0\n",
    " - Count = 1\n",
    " - Count = 2\n",
    " - Count >= 3\n",
    "\n",
    "**Juvenile Misdemeanor Count** --\n",
    "A count of the number of misdemeanor convictions this individual has as a minor (juvenile).\n",
    "As with juvenile felony count above, this feature was originally an integer value,\n",
    "but for this assignment it was transformed into a feature with four categorical values representing\n",
    "the same ranges/bins of counts as above (namely: 0, 1, 2, >=3).\n",
    "\n",
    "**Juvenile \"Other\" Count** --\n",
    "A count of the number of non-felony/non-misdemeanor convictions this individual has as a minor (juvenile).\n",
    "Such \"other\" convictions are less severe than felonies and misdemeanors (i.e., infractions).\n",
    "This feature was also originally an integer value, but was transformed into a feature with four categorical values\n",
    "representing the same ranges/bins of counts as above (namely: 0, 1, 2, >=3).\n",
    "\n",
    "**Prior Convictions Count** --\n",
    "A count of the total number of prior convictions this individual has had as an adult.\n",
    "This feature was also originally an integer value,\n",
    "but was transformed into a feature with four categorical values representing the same ranges/bins of counts as above (namely: 0, 1, 2, >=3).\n",
    "\n",
    "**Degree of Charge** --\n",
    "The degree of the current charge that this individual is facing.\n",
    "The only possible values for this feature are: \"felony\" or \"misdemeanor\".\n",
    "\n",
    "**Description of Charge** --\n",
    "The type of crime with which the individual is being charged.\n",
    "Originally, this feature had over 400 possible values, but they were consolidated into one of the following 12 high-level categories:\n",
    " - No charge\n",
    " - License issue\n",
    " - Public disturbance\n",
    " - Negligence\n",
    " - Drug-related\n",
    " - Alcohol-related\n",
    " - Weapons-related\n",
    " - Evading arrest\n",
    " - Nonviolent harm (i.e. stalking, tampering with victim, property damage, etc.)\n",
    " - Theft/fraud/burglary\n",
    " - Lewdness/prostitution\n",
    " - Violent crimes\n",
    "\n",
    "**Age** --\n",
    "The individual's age at the time of arrest.\n",
    "Originally, this feature was simply an integer value,\n",
    "but for this assignment it was transformed into a feature with three categorical values representing ranges of ages\n",
    "(to match the same age bins used in the ProPublica analysis for this feature).\n",
    "Those age ranges/bins are:\n",
    " - Less than 25 years old\n",
    " - 25 to 45 years old\n",
    " - Greater than 45 years old\n",
    "\n",
    "**Gender** --\n",
    "The individual's gender.\n",
    "To match the COMPAS data, this was artificially restricted to \"female\" and \"male\".\n",
    "\n",
    "**Race** --\n",
    "The individual's race.\n",
    "This feature has six values:\n",
    " - Other (i.e., none of the races below)\n",
    " - Asian\n",
    " - Native American\n",
    " - Caucasian (same as \"White\" in the ProPublica analysis)\n",
    " - Hispanic\n",
    " - African-American (same as \"Black\" in the ProPublica analysis)\n",
    "\n",
    "Now that we have a basic overview of the data, let's load it and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93457f17-63f5-448e-bb5b-66002ae9149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries we will need.\n",
    "# It is good style to make all your imports in the first cell of the notebook.\n",
    "\n",
    "import random\n",
    "import traceback\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn.linear_model\n",
    "import math\n",
    "\n",
    "# Set a global seed in case we need some randomness.\n",
    "random.seed(146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358477fc-67ce-47b4-94db-ec0cf0977f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "recidivism_train = pandas.read_csv(\"recidivism-training-data.csv\")\n",
    "recidivism_test = pandas.read_csv(\"recidivism-testing-data.csv\")\n",
    "\n",
    "recidivism_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2216d-0edc-464d-bbdd-fe3ea49fdcab",
   "metadata": {},
   "source": [
    "Here we can clearly see all the binary features mentioned above,\n",
    "where 1 is `True` and 0 is `False`.\n",
    "We can verify the type of each column using `DataFrame.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391497fe-fdcd-4faf-b7eb-4bc882114b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recidivism_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178a0d6-9664-4f07-af3e-081d213edef6",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: x-large\";>♦ Group Break</h3>\n",
    "\n",
    "Take a moment to examine the data with your group.\n",
    "\n",
    "Some potential things to discuss with your group:\n",
    " - Why was the data binarized (converted to all 0/1)?\n",
    " - Do all of these features seem \"fair\" to use?\n",
    " - Do any features seem like they could be misused or taken advantage of?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc5174b-9b6a-48d9-911d-64a30f372755",
   "metadata": {},
   "source": [
    "As with in Lab 1, let's shuffle our data and then split into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f5f2a-fdfd-4a1d-a281-1100b82d2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "recidivism_train = recidivism_train.sample(frac = 1, ignore_index = True, random_state = 146)\n",
    "recidivism_test = recidivism_test.sample(frac = 1, ignore_index = True, random_state = 146)\n",
    "\n",
    "def split_features(label_column_name, train, test):\n",
    "    feature_column_names = list(train.columns)\n",
    "    feature_column_names.remove(label_column_name)\n",
    "    \n",
    "    features_train = train[feature_column_names]\n",
    "    labels_train = train[label_column_name]\n",
    "    \n",
    "    features_test = test[feature_column_names]\n",
    "    labels_test = test[label_column_name]\n",
    "\n",
    "    return features_train, labels_train, features_test, labels_test\n",
    "\n",
    "recidivism_features_train, recidivism_labels_train, recidivism_features_test, recidivism_labels_test = split_features('Recidivate', recidivism_train, recidivism_test)\n",
    "print(\"Features and labels split.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff0dd9-e895-4204-81e9-7e1222b5ad99",
   "metadata": {},
   "source": [
    "Now that we have data, let's just try out an initial model.\n",
    "A big part of machine learning is exploration and intuition.\n",
    "So instead of taking too much time theorizing about what the data *could* contain and how a model *could* perform,\n",
    "sometimes it is best to just try out something simple and see how it goes.\n",
    "\n",
    "We already have basic experience training and evaluating models from Lab 1,\n",
    "so let's take the same approach here.\n",
    "We will start with a simple Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ec2d1-545c-4142-aa1f-aad066869a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = sklearn.linear_model.LogisticRegression()\n",
    "classifier.fit(recidivism_features_train, recidivism_labels_train)\n",
    "score = classifier.score(recidivism_features_test, recidivism_labels_test)\n",
    "print(\"Initial Logistic Regression Score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdae976-42e5-4b9f-8ed6-e1620b72ee35",
   "metadata": {},
   "source": [
    "That's an okay score, not great but fine for a first try.\n",
    "In this assignment, we will not be focusing on how we can improve our prediction score.\n",
    "Instead, we will be focusing on seeing what features contribute to that score,\n",
    "and how changing the sets of features we use can affect the model.\n",
    "\n",
    "In this case, a single score is not good enough (especially accuracy) to see what is happening in our model.\n",
    "As discussed in Lab 1, choosing evaluation metrics is critical not just to the success of your model,\n",
    "but also critical to creating ethical models.\n",
    "We need to see more metrics to see how our model is actually doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351314e7-09e0-465a-99c4-1d8e187f5ddc",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange; font-size: x-large\";>★ Task 1.A</h3>\n",
    "\n",
    "Complete the function below that takes in the output from a classifier (predictions) and true labels,\n",
    "and returns a dict that contains that following information (see example output below for exact keys):\n",
    " - A [Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    " - Accuracy\n",
    " - [Precision](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    " - [Recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    " - [F1 Score](https://en.wikipedia.org/wiki/F-score)\n",
    " - [False Negative Rate](https://en.wikipedia.org/wiki/False_positives_and_false_negatives#false_negative_rate)\n",
    " - [False Positive Rate](https://en.wikipedia.org/wiki/False_positive_rate)\n",
    "\n",
    "Whenever a computation would divide by zero, use a `numpy.nan`.\n",
    "\n",
    "Hint:\n",
    "Aside from the confusion matrix itself, all of these stats can be computed from a confusion matrix.\n",
    "Therefore, you may find the [sklearn.metrics.confusion_matrix()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function useful here.\n",
    "\n",
    "Example Output:\n",
    "```json\n",
    "{\n",
    "    \"confusion_matrix\": {\n",
    "        \"tp\": 1,\n",
    "        \"fn\": 2,\n",
    "        \"fp\": 3,\n",
    "        \"tn\": 4,\n",
    "    },\n",
    "    \"accuracy\": 0.500,\n",
    "    \"precision\": 0.250,\n",
    "    \"recall\": 0.333,\n",
    "    \"f1\": 0.286,\n",
    "    \"fnr\": 0.667,\n",
    "    \"fpr\": 0.429,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b53b04-c88a-477e-a261-5256c0247d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(predictions, labels):\n",
    "    \"\"\"\n",
    "    Get scoring stats for the provided predictions and labels.\n",
    "\n",
    "    Example output:\n",
    "    {\n",
    "        \"confusion_matrix\": {\n",
    "            \"tp\": 1,\n",
    "            \"fn\": 2,\n",
    "            \"fp\": 3,\n",
    "            \"tn\": 4,\n",
    "        },\n",
    "        \"accuracy\": 0.500,\n",
    "        \"precision\": 0.250,\n",
    "        \"recall\": 0.333,\n",
    "        \"f1\": 0.286,\n",
    "        \"fnr\": 0.667,\n",
    "        \"fpr\": 0.429,\n",
    "    }\n",
    "\n",
    "    Returns:\n",
    "        A dict with full scoring information (see above).\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "def print_stats(stats):\n",
    "    if (stats is NotImplemented):\n",
    "        print(\"Stats have not been implemented.\")\n",
    "        return\n",
    "        \n",
    "    stats = stats.copy()\n",
    "\n",
    "    matrix = stats.pop('confusion_matrix')\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"                Predicted\")\n",
    "    print(\"               True  | False\")\n",
    "    print(\"        True  % 3d   | % 3d  \" % (matrix['tp'], matrix['fn']))\n",
    "    print(\"Actual        -------------\")\n",
    "    print(\"        False % 3d   | % 3d  \" % (matrix['fp'], matrix['tn']))\n",
    "    print()\n",
    "\n",
    "    for name, value in stats.items():\n",
    "        print(\"%9s: %0.3f\" % (name, value))\n",
    "\n",
    "predictions = classifier.predict(recidivism_features_test)\n",
    "\n",
    "stats = get_stats(predictions, recidivism_labels_test)\n",
    "print_stats(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f0120-14a7-478e-90b5-d597551c0519",
   "metadata": {},
   "source": [
    "Now we can get a much more complete picture of our model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379161c-d329-4fc5-8525-b13ccbb1da79",
   "metadata": {},
   "source": [
    "## Part 2: Logistic Regression and Feature Weights\n",
    "\n",
    "[Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression) is a great choice for a first classifier to use when exploring data.\n",
    "Although there will often be better models to use in the end,\n",
    "Logistic Regression is a strong \"all-around\" model that is rarely the worst in practice.\n",
    "Logistic Regression also falls into a family of models called [general linear models](https://en.wikipedia.org/wiki/General_linear_model),\n",
    "which are easier to interpret than many other families of models (like clustering or non-linear (e.g. neural) models).\n",
    "\n",
    "General linear models work by applying a function to a linear combination of all features before making a prediction:\n",
    "$$\n",
    "\\hat{y}(x, b, w) = f( b + w \\cdot x )\n",
    "$$\n",
    "\n",
    "Where $ b $ is called the \"bias\" (not to be confused with a ethical/fairness bias),\n",
    "$ w $ is a vector of weights/coefficients (one for each feature),\n",
    "and $ f $ is some function that is applied to the result of the linear combinations.\n",
    "Logistic regression uses the [logistic function](https://en.wikipedia.org/wiki/Logistic_function) for $ f $.\n",
    "There are a lot of very interesting reasons, benefits, and trade-offs associated with using the logistic function,\n",
    "but those are outside the scope of this course.\n",
    "All we need to know about the logistic function for this lab is that it tends to produce values that are close to either $ 0.0 $ or $ 1.0 $.\n",
    "As we can see below, large values produce a result near $ 1.0 $, and small values produce a result near $ 0.0 $.\n",
    "\n",
    "<center><img src=\"logistic.png\" style=\"background-color: white\" width=\"500px\"/></center>\n",
    "<center style='font-size: small'>Image courtesy of <a href='https://en.wikipedia.org/wiki/File:Logistic-curve.svg'>Wikimedia Commons</a>.</center>\n",
    "\n",
    "Instead of analyzing the logistic function more, what we are really interested in here is $ w $,\n",
    "the vector of weights (one for each feature).\n",
    "As we see above, large inputs into the logistic function produce outputs\n",
    "(in our case these are predictions) close to $ 1.0 $.\n",
    "Therefore if the linear combination of is large, our Logistic Regression model will predict closer to 1 (true).\n",
    "We can also look at it like this:\n",
    "\n",
    "$$\n",
    "\\hat{y}(x, b, w) \\sim \\sum_{i = 1}^{|x|} w_i * x_i\n",
    "$$\n",
    "\n",
    "This means that after training our Logistic Regression model\n",
    "(which will learn values for $ b $ and $ w $),\n",
    "we can look at the values of $ w $ to see which features our model prioritizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63eb50-35d1-49fb-86b7-a77e94b49fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model.\n",
    "classifier = sklearn.linear_model.LogisticRegression()\n",
    "classifier.fit(recidivism_features_train, recidivism_labels_train)\n",
    "\n",
    "# Output the feature weights.\n",
    "classifier.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c428355-5352-44b9-a365-4e0a81f5e3e4",
   "metadata": {},
   "source": [
    "Cool, we can see the weights (also called \"coefficients\") for our model.\n",
    "But this dump of numbers is hard to look at alone,\n",
    "so let's match these weights up to the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f78ee3-4ac9-4ac3-b43e-968309120ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(feature_names, weights):\n",
    "    if ((feature_names is NotImplemented) or (weights is NotImplemented)):\n",
    "        print(\"Data is NotImplemented.\")\n",
    "        return\n",
    "        \n",
    "    # Pair up weights and feature names so we can sort them.\n",
    "    pairs = []\n",
    "    for i in range(len(feature_names)):\n",
    "        pairs.append((weights[i], feature_names[i]))\n",
    "\n",
    "    # Sort the pairs with largest value first.\n",
    "    pairs = list(sorted(pairs, reverse = True))\n",
    "    \n",
    "    print(\"Feature weights: \")\n",
    "    for (weight, name) in pairs:\n",
    "        print(\"    % 0.4f -- %s\" % (weight, name))\n",
    "\n",
    "recidivism_feature_names = list(recidivism_features_train.columns)\n",
    "# Note that in the above output, coef_ is a 2d array.\n",
    "recidivism_weights = classifier.coef_[0]\n",
    "\n",
    "print_weights(recidivism_feature_names, recidivism_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e5004-f5cb-4998-be7a-ef553371e753",
   "metadata": {},
   "source": [
    "Now we can clearly see how our Logistic Regression model treats each feature.\n",
    "Features with a large (positive or negative) weight will have more impact on our predictions.\n",
    "So, our three most impactful features are:\n",
    " - `Prior conviction count >= 3` with a weight of 0.8548.\n",
    " - `Age < 25` with a weight of 0.5908.\n",
    " - `Prior conviction count = 0` with a weight of -0.5688.\n",
    "\n",
    "As we look at the features,\n",
    "consider a positive side effect of binarizing our features.\n",
    "By making sure that all numeric features are 0/1,\n",
    "we ensured that they are all within the same scale and can be easily compared when looking at their weights.\n",
    "If we just left each numeric feature alone,\n",
    "different features could have different domains.\n",
    "For example, age (in years) and height (in feet) may get similar weights in a hypothetical model,\n",
    "but age in this case would actually have more impact in our model (since we will generally be an order of magnitude larger than height)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dbc5b8-0123-450e-bf48-cf70cf1f724d",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: x-large\";>♦ Group Break</h3>\n",
    "\n",
    "Take a moment to think about feature weights in a model.\n",
    "\n",
    "Some potential things to discuss with your group:\n",
    " - Is there a limit on what numeric values our features can be?\n",
    " - Can positive weights contribute to negative labels (and vice versa)?\n",
    " - Can you think of a way general linear models can capture more complex feature interactions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f502e-30fa-4b12-b58a-55287b246f4c",
   "metadata": {},
   "source": [
    "## Part 3: Feature Selection\n",
    "\n",
    "Now that we can see the feature weights that make up our model,\n",
    "let's see how our model changes as we use different subsets of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb8363-6793-4d42-8156-385ef02a66e4",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange; font-size: x-large\";>★ Task 3.A</h3>\n",
    "\n",
    "Complete the function below that takes a list of feature names, a matching list of feature weights, and some matching information;\n",
    "and returns a list of feature names that match the given conditions.\n",
    "\n",
    "Matching Conditions:\n",
    " - `lower_than` (default: `numpy.inf`) -- Match features with a weight lower than this value.\n",
    " - `higher_than` (default: `-numpy.inf`) -- Match features with a weight higher than this value.\n",
    " - `use_and` (default: `True`) -- Use a logical and (conjunction) when matching conditions, otherwise use a logical or (disjunction).\n",
    "\n",
    "Note the use of `numpy.inf` (positive infinity) and `-numpy.inf` (negative infinity) as default values.\n",
    "By using the maximum (an minimum) possible values,\n",
    "everything is included by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1d1c2-bfd3-44ff-85b2-1cc4c75af817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_by_weight(feature_names, weights, lower_than = numpy.inf, higher_than = -numpy.inf, use_and = True):\n",
    "    \"\"\"\n",
    "    Take in two matching lists of feature names and weights,\n",
    "    and return feature names that match the specified criteria.\n",
    "\n",
    "    Returns:\n",
    "        A list of matching feature names.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented\n",
    "\n",
    "recidivism_positive_features = select_features_by_weight(recidivism_feature_names, recidivism_weights, higher_than = 0.0)\n",
    "recidivism_positive_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a52544-69ea-403a-a55c-814ada20ddaf",
   "metadata": {},
   "source": [
    "Here we can see all the positive features\n",
    "(features that positively correlate with a positive label).\n",
    "\n",
    "But what may be more useful is seeing features that have a high magnitude (regardless of sign).\n",
    "These will be features that have a large influence over our model.\n",
    "\n",
    "For this lab, we have arbitrarily chosen 0.3 as the threshold for a \"large\" magnitude for a feature.\n",
    "There is no theory or validation behind this choice, just intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad13473-aee0-40e5-86b2-e9ec8ca2dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features_by_weight(recidivism_feature_names, recidivism_weights, higher_than = 0.3, lower_than = -0.3, use_and = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2abb55-881d-43d1-a579-ffca121932ac",
   "metadata": {},
   "source": [
    "Now that we can filter out \"weak\" and \"strong\" features,\n",
    "let's build some models around those features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e600ba1-8600-4702-9f45-2b1c5a9ad13c",
   "metadata": {},
   "source": [
    "<h3 style=\"color: darkorange; font-size: x-large\";>★ Task 3.B</h3>\n",
    "\n",
    "Complete the function below that takes a full dataset and a list of column names to use,\n",
    "and returns the weights of a trained Logistic Regression model as well as the stats from your `get_stats()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498db95-623e-42af-8b34-e18fa67b3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_subset_features(features_train, labels_train, features_test, labels_test, selected_feature_names):\n",
    "    \"\"\"\n",
    "    Take in all parts of a full dataset,\n",
    "    and return the weights for a trained model and stats.\n",
    "\n",
    "    Returns:\n",
    "        A list of weights from a Logistic Regression classifier trained on the passed in data.\n",
    "        The stats for this classifier/dataset as computed by `get_stats()`.\n",
    "    \"\"\"\n",
    "\n",
    "    return NotImplemented, NotImplemented\n",
    "\n",
    "weights, stats = test_subset_features(recidivism_features_train, recidivism_labels_train, recidivism_features_test, recidivism_labels_test, recidivism_positive_features)\n",
    "if (weights is NotImplemented):\n",
    "    print(\"Function not implemented.\")\n",
    "else:\n",
    "    print(\"Weights: \", weights)\n",
    "    print_stats(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e856ea-aa74-4f51-9197-890d634b2f78",
   "metadata": {},
   "source": [
    "With this new function, we should be able to test out different feature combinations pretty quickly.\n",
    "But, we can make an ever more convenient function that puts together everything we have done in this lab.\n",
    "We will also have this function (optionally) save the stats that it computes in a global variable called `_saved_stats` so that we can access them all later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a5b88-2caa-4d2b-b3b7-a4f45b7cc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A super-function that puts everything together so we can test quickly!\n",
    "def test_and_print_subset_features(label_column_name, train, test,\n",
    "                                   lower_than = numpy.inf, higher_than = -numpy.inf, use_and = True,\n",
    "                                   override_selected_columns = None,\n",
    "                                   save_stats_key = None):\n",
    "    try:\n",
    "        _test_and_print_subset_features(label_column_name, train, test,\n",
    "                                        lower_than, higher_than, use_and,\n",
    "                                        override_selected_columns, save_stats_key)\n",
    "    except Exception as ex:\n",
    "        print(\"Encountered the following exception, have you implemented all the required functions yet?\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "# Use a private(ish) subroutine so we can more easily catch exceptions.\n",
    "def _test_and_print_subset_features(label_column_name, train, test,\n",
    "                                    lower_than, higher_than, use_and,\n",
    "                                    override_selected_columns, save_stats_key):\n",
    "    features_train, labels_train, features_test, labels_test = split_features(label_column_name, train, test)\n",
    "                                       \n",
    "    base_classifier = sklearn.linear_model.LogisticRegression()\n",
    "    base_classifier.fit(features_train, labels_train)\n",
    "\n",
    "    if (override_selected_columns is not None):\n",
    "        selected_columns = override_selected_columns\n",
    "    else:\n",
    "        feature_names = list(features_train.columns)\n",
    "        base_weights = base_classifier.coef_[0]\n",
    "        selected_columns = select_features_by_weight(feature_names, base_weights, lower_than = lower_than, higher_than = higher_than, use_and = use_and)\n",
    "\n",
    "    weights, stats = test_subset_features(features_train, labels_train, features_test, labels_test, selected_columns)\n",
    "\n",
    "    if ((weights is NotImplemented) or (stats is NotImplemented)):\n",
    "        print(\"Functions have not been implemented.\")\n",
    "        return\n",
    "\n",
    "    print_stats(stats)\n",
    "    print()\n",
    "    print_weights(selected_columns, weights)\n",
    "\n",
    "    if (save_stats_key is not None):\n",
    "        # Do some fancy moves to make sure that _saved_stats is defined and updated outside of this function.\n",
    "        global _saved_stats\n",
    "        _saved_stats = globals().get('_saved_stats', None)\n",
    "        \n",
    "        if (_saved_stats is None):\n",
    "            _saved_stats = {}\n",
    "        _saved_stats[save_stats_key] = stats\n",
    "\n",
    "    return stats\n",
    "\n",
    "test_and_print_subset_features('Recidivate', recidivism_train, recidivism_test, save_stats_key = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109d026-2432-4a0f-82ca-672ef504b0e8",
   "metadata": {},
   "source": [
    "Great,\n",
    "now we can test collections of features and see their stats all in one call.\n",
    "With this, we can look into what happens when we use a subset of the features on this dataset.\n",
    "\n",
    "Let's start with what happens when we only use the larger features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f995857-9047-4315-8f9f-f73c0e8e8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_print_subset_features('Recidivate', recidivism_train, recidivism_test,\n",
    "                               higher_than = 0.3, lower_than = -0.3, use_and = False,\n",
    "                               save_stats_key = 'large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c88ce7-c6c6-4ae6-b78a-136e8fddc280",
   "metadata": {},
   "source": [
    "With only the \"large\" features, we can see that we perform almost as well as the model with all the features (according to accuracy and F1 score).\n",
    "This is pretty expected, since we used all the most influential features.\n",
    "Note that the weights for each feature are different in this model because with a different set of features the model has a slightly different learning problem.\n",
    "\n",
    "It is pretty interesting that our model with only 17 features performed almost as well as the base model with 41 features.\n",
    "In this case, the number of feature is not too great (to a computer),\n",
    "but you can imagine that for models with thousands or millions of feature,\n",
    "removing irrelevant features could be pretty useful.\n",
    "\n",
    "Now let's try a model with only the large positive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf002d5-2ed0-4a9f-97e5-088a9280e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_print_subset_features('Recidivate', recidivism_train, recidivism_test,\n",
    "                               higher_than = 0.3,\n",
    "                               save_stats_key = 'large positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318ca0e-330f-49ac-83fa-654035b76318",
   "metadata": {},
   "source": [
    "Once again, we did pretty well.\n",
    "Not as well as the base model or \"large\" model,\n",
    "but pretty close with just a handful of the features.\n",
    "\n",
    "What about if we use the large negative features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d913bf-72cd-46bb-a778-391de3690478",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_print_subset_features('Recidivate', recidivism_train, recidivism_test,\n",
    "                               lower_than = -0.3,\n",
    "                               save_stats_key = 'large negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e312a5-cc6f-4373-9bea-31f1d7823757",
   "metadata": {},
   "source": [
    "Interestingly, we did slightly better than the large positive features.\n",
    "Perhaps not better enough to be considered significant, but still a little better.\n",
    "But, we can also say that these large negative features did about the same as the large positive features.\n",
    "\n",
    "What if we only used \"small\" features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd312d3a-7df9-41b9-8218-c8a3293ffaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_print_subset_features('Recidivate', recidivism_train, recidivism_test,\n",
    "                               higher_than = -0.3, lower_than = 0.3,\n",
    "                               save_stats_key = 'small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfc964-3aa4-47d0-bec9-b7d1848f5d95",
   "metadata": {},
   "source": [
    "As expected, this model was the worst of them all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc7a3d-318e-4b25-8f2f-1330dbabf74a",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: x-large\";>♦ Group Break</h3>\n",
    "\n",
    "Take a moment to think about the performance of our model with different sets of features.\n",
    "\n",
    "Some potential things to discuss with your group:\n",
    " - Is there any reason we would just not use all the features?\n",
    " - Are either the positive or negative features better than the other?\n",
    " - Could a feature weight switch from positive to negative (or vice versa) between the base model with all the features and a model with only a subset of the features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eb1ab5-41b6-4862-91d2-2ca604ffdbce",
   "metadata": {},
   "source": [
    "### Protected Attributes\n",
    "\n",
    "[\"Protected Attributes\"](https://en.wikipedia.org/wiki/Protected_group) generally refer to attributes/features that should not be used to make decisions.\n",
    "There are specific organizations and situations where certain attributes are legally protected.\n",
    "For example, in the US it is considered discrimination to not hire someone based on their age, gender, race,\n",
    "and other attributes (the exact set of attributes may be debated on a state-by-state basis).\n",
    "\n",
    "Let's collect some protected attributes for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0429162-a328-4c0a-9069-336242852039",
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_keywords = ['age', 'gender', 'race']\n",
    "\n",
    "protected_columns = []\n",
    "for column_name in recidivism_features_train.columns:\n",
    "    match = False\n",
    "    for protected_keyword in protected_keywords:\n",
    "        if (protected_keyword in column_name.lower()):\n",
    "            match = True\n",
    "            break\n",
    "\n",
    "    if (match):\n",
    "        protected_columns.append(column_name)\n",
    "\n",
    "non_protected_columns = list(set(recidivism_features_train.columns) - set(protected_columns))\n",
    "\n",
    "print(\"Protected Columns:\")\n",
    "print(\"    \" + \"\\n    \".join(protected_columns))\n",
    "print()\n",
    "print(\"Non-Protected Columns:\")\n",
    "print(\"    \" + \"\\n    \".join(non_protected_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a1cb9-2077-4c4d-8ed1-10fe709d5e9e",
   "metadata": {},
   "source": [
    "Now that we have protected (and non-protected) features,\n",
    "let's see what happens when we remove all protected features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce8ed0-9c0e-4efc-bf80-37067213a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_print_subset_features('Recidivate', recidivism_train, recidivism_test,\n",
    "                               override_selected_columns = non_protected_columns,\n",
    "                               save_stats_key = 'non-protected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b0fb3-5f16-4e51-9b2a-d8a68c1a3f6a",
   "metadata": {},
   "source": [
    "Interestingly, we see almost the same performance as when we used large positive features.\n",
    "So as long as none of our features are [proxies for protected attributes](https://towardsdatascience.com/algorithm-fairness-sources-of-bias-7082e5b78a2c),\n",
    "we can remove all protected features from our model without substantially hurting performance.\n",
    "\n",
    "Now what happens when we remove all protected features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abccb8-4d3f-4edb-bf1d-f5128ebcda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_print_subset_features('Recidivate', recidivism_train, recidivism_test,\n",
    "                               override_selected_columns = protected_columns,\n",
    "                               save_stats_key = 'protected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5877e-14c9-4b71-98f2-f9e29711fccf",
   "metadata": {},
   "source": [
    "This version of the model does not do well at all.\n",
    "Not only are the accuracy worse than most of the versions we have seen,\n",
    "but the F1 is way worse and false negative rate is way higher (which is bad).\n",
    "\n",
    "It can be hard to remember all these numbers, so let's make a function to help is plot bar graphs of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2afde2e-2d08-433c-ae94-9a9877fdd681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
    "def plot_bar(groups, data, title, x_label, y_label,\n",
    "             y_min = 0.0, y_max = 1.0,\n",
    "             round_digits = 3,\n",
    "             sort_keys = None, sort_reverse = True,\n",
    "             width_in = 14, height_in = 6):\n",
    "    x = numpy.arange(len(groups))\n",
    "    width = 1.0 / (len(data) + 1)\n",
    "    multiplier = 0\n",
    "\n",
    "    data = data.copy()\n",
    "    \n",
    "    matplotlib.pyplot.subplots(layout = 'constrained')\n",
    "\n",
    "    if (sort_keys is not None):\n",
    "        sort_pairs = []\n",
    "        for index in range(len(groups)):\n",
    "            pair = []\n",
    "            for sort_key in sort_keys:\n",
    "                pair.append(data[sort_key][index])\n",
    "\n",
    "            pair.append(index)\n",
    "            sort_pairs.append(pair)\n",
    "\n",
    "        sort_pairs.sort(reverse = sort_reverse)\n",
    "\n",
    "        new_data = {}\n",
    "        for (name, values) in data.items():\n",
    "            new_data[name] = []\n",
    "            for pair in sort_pairs:\n",
    "                new_data[name].append(data[name][pair[-1]])\n",
    "\n",
    "        data = new_data\n",
    "\n",
    "    if (round_digits is not None):\n",
    "        for name in data:\n",
    "            for i in range(len(data[name])):\n",
    "                data[name][i] = round(data[name][i], round_digits)\n",
    "        \n",
    "    for attribute, measurement in data.items():\n",
    "        offset = width * multiplier\n",
    "        rects = matplotlib.pyplot.bar(x + offset, measurement, width, label = attribute)\n",
    "        matplotlib.pyplot.bar_label(rects, padding = 10)\n",
    "        multiplier += 1\n",
    "    \n",
    "    matplotlib.pyplot.xlabel(x_label)\n",
    "    matplotlib.pyplot.ylabel(y_label)\n",
    "    matplotlib.pyplot.title(title)\n",
    "    matplotlib.pyplot.xticks(x + (width * ((len(data) / 2) - 0.5)), groups)\n",
    "    matplotlib.pyplot.legend()\n",
    "    matplotlib.pyplot.ylim(y_min, y_max)\n",
    "                 \n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(width_in, height_in)\n",
    "    \n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238822f8-d34d-4041-a6c7-98fef530b6fd",
   "metadata": {},
   "source": [
    "Now we can use all the stats we have computed and saved (in `_saved_stats`) to plot our results in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280d68a-565f-4298-9f5f-063a4f23d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_saved_stats = globals().get('_saved_stats', None)\n",
    "if (_saved_stats is None):\n",
    "    print(\"No stats have been saved.\")\n",
    "else:\n",
    "    names = list(sorted(_saved_stats.keys()))\n",
    "    data = {\n",
    "        'accuracy': [_saved_stats[name]['accuracy'] for name in names],\n",
    "        'f1': [_saved_stats[name]['f1'] for name in names],\n",
    "    }\n",
    "    sort_keys = ['accuracy', 'f1']\n",
    "    \n",
    "    plot_bar(names, data, 'Feature Set Stats', 'Metric', 'Value',\n",
    "             sort_keys = sort_keys, round_digits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a8156-ed26-48d1-801e-7ee28172cf1b",
   "metadata": {},
   "source": [
    "This is interesting, but is still missing parts of the story.\n",
    "Recall from Lab 1 that we also discussed FNR and FPR.\n",
    "How do those types of errors work here?\n",
    "\n",
    "Let's graph them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea0bda-75c7-483d-b67b-edbb3450e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_saved_stats = globals().get('_saved_stats', None)\n",
    "if (_saved_stats is None):\n",
    "    print(\"No stats have been saved.\")\n",
    "else:\n",
    "    names = list(sorted(_saved_stats.keys()))\n",
    "    data = {\n",
    "        'accuracy': [_saved_stats[name]['accuracy'] for name in names],\n",
    "        'f1': [_saved_stats[name]['f1'] for name in names],\n",
    "        'fnr': [_saved_stats[name]['fnr'] for name in names],\n",
    "        'fpr': [_saved_stats[name]['fpr'] for name in names],\n",
    "    }\n",
    "    sort_keys = ['accuracy', 'f1']\n",
    "    \n",
    "    plot_bar(names, data, 'Feature Set Stats', 'Metric', 'Value',\n",
    "             sort_keys = sort_keys, round_digits = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2240ba-2490-4699-801d-fdbd43c81509",
   "metadata": {},
   "source": [
    "Very interesting!\n",
    "There is a lot to break down in these graphs.\n",
    "Remember that high accuracy and F1 is good,\n",
    "but high FNR and FPR is bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b21310-ea9a-4170-a3eb-d3ef130bf5f9",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: x-large\";>♦ Group Break</h3>\n",
    "\n",
    "Take a moment to think about the performance of our model with different sets of features.\n",
    "\n",
    "Some potential things to discuss with your group:\n",
    " - What insights (if any) can you extract from the graphs above?\n",
    " - Using the protected attributes clearly shows that there is a problem not seen in the other feature sets. What could explain this?\n",
    " - In this dataset, do we need protected attributes?\n",
    "     - Should the protected attributes even be included in our model?\n",
    "     - Why were they included in the COMPAS data?\n",
    " - What type of error (False Negative vs False Positive) is more harmful in this setting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67c376-cb5a-4cd0-9c41-bcfdadbbbd28",
   "metadata": {},
   "source": [
    "## Part 4: Short Response Questions\n",
    "\n",
    "Please go to Canvas to enter your group's responses to the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768ad4a-099b-4849-9774-7b5cbf60a9fa",
   "metadata": {},
   "source": [
    "#### Q1\n",
    "\n",
    "The data we used includes protected attributes.\n",
    "Does that mean that the base model we created from it (using all the features) is inherently biased?\n",
    "Can you prove that model using all the data is or is not biased?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f984f-4e0d-4c90-a3c2-fa40f741ff1e",
   "metadata": {},
   "source": [
    "#### Q2\n",
    "\n",
    "In this dataset, we saw that using only non-protected attributes only slightly impacted our performance metrics.\n",
    "Assuming that the differences we saw are statistically significant,\n",
    "do we need to protected attributes?\n",
    "\n",
    "Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e0100-49dd-4591-a6a4-ce12e52ac4a2",
   "metadata": {},
   "source": [
    "#### Q3\n",
    "\n",
    "If using protected attributes did create a substantially better model\n",
    "(and there were no legal issues),\n",
    "should we include the protected attributes in our model?\n",
    "\n",
    "Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45de82b-ed8f-49cc-9cf0-d61f6a0e10ff",
   "metadata": {},
   "source": [
    "#### Q4\n",
    "\n",
    "Can data that has no protected attributes still be biased?\n",
    "Why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5524ac-3094-4b6b-9f0f-79f99bef85da",
   "metadata": {},
   "source": [
    "#### Q5\n",
    "\n",
    "What type of error (False Negative vs False Positive) is more harmful in this setting?\n",
    "\n",
    "Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44b344f-a33b-4004-9b2e-65795181b320",
   "metadata": {},
   "source": [
    "#### Q6\n",
    "\n",
    "After doing this lab, what are your views on the COMPAS model with respect to bias and racism?\n",
    "\n",
    "Do you believe that a machine learning model should be used to predict criminal recidivism?\n",
    "Why or why not?\n",
    "Does the context matter?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
